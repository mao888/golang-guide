# 重点名词解释
| **名词** | **是什么** | **类比** |
| --- | --- | --- |
| **LLM** | 大脑 | 人 |
| **RAG** | 查资料 | 搜索引擎 |
| **Agent** | 会干活的 AI | 员工 |
| **LangChain** | 开发框架 | Spring |
| **LangGraph** | 工作流引擎 | Temporal |
| **MCP** | 工具通信协议 | gRPC |


## 先理解一个核心：LLM 是什么？
LLM（Large Language Model）= 大语言模型  
比如：

+ OpenAI 的 GPT
+ Anthropic 的 Claude
+ Alibaba 的 Qwen（通义千问）

本质：

一个“超强文本预测机器”

它能：

+ 理解问题
+ 推理
+ 写代码
+ 总结
+ 决策

但有一个大问题：

❌ 它自己不能访问数据库  
❌ 不能调用你的接口  
❌ 不能查实时数据  
❌ 不能执行程序

它只是一个“会思考的大脑”。

## RAG 是什么？
RAG = Retrieval-Augmented Generation  
中文叫：**检索增强生成**

一句话理解：

让 LLM 先去“查资料”，再回答问题

因为：

LLM 本身：

+ 不知道你公司数据库
+ 不知道你内部文档
+ 不知道最新数据

RAG 解决方案：

```plain
用户问题
   ↓
去知识库/数据库查资料
   ↓
把查到的内容喂给 LLM
   ↓
LLM 再生成答案
```

举个你能理解的例子：

你做广告中台系统。

用户问：

“最近三天哪个广告转化率最高？”

普通 LLM：不知道  
RAG 流程：

1. 查数据库
2. 把结果拼进 Prompt
3. 让 LLM 总结

这就是 RAG。

## Agent 是什么？
这是最关键的概念。

Agent = 会思考 + 会调用工具 + 会执行任务的 AI

区别：

### 传统后端
你写死逻辑：

```plain
if A {
   call service1
} else {
   call service2
}
```

### Agent
LLM 自己决定：

```plain
Step1: 我需要查数据库
Step2: 调用 DB 工具
Step3: 需要分析
Step4: 生成报告
```

Agent =

LLM + 工具调用 + 决策能力

## LangChain 是什么？
LangChain

LangChain 是一个：

帮你搭建 Agent 的框架

它帮你做：

+ 调 LLM
+ 管理 Prompt
+ 管理工具
+ 管理对话上下文
+ 管理 RAG

就像：

+ Gin 是 Web 框架
+ Gorm 是 ORM
+ LangChain 是 Agent 框架

你可以理解为：

AI 时代的 Spring Boot

## LangGraph 是什么？
LangGraph 是：

专门做“复杂 Agent 工作流”的框架

区别在于：

LangChain 偏简单链式调用：

```plain
A → B → C
```

LangGraph 支持：

```plain
判断 → 分支 → 循环 → 多节点协作
```

更像：

+ 工作流引擎
+ 有状态的 DAG

如果你熟悉：

+ 状态机
+ 工作流引擎
+ 编排系统

LangGraph 很好理解。



## MCP 是什么？
MCP = Model Context Protocol

是 Anthropic 提出的协议。

简单讲：

让 LLM 用“标准协议”访问外部工具

相当于：

```plain
LLM ←→ 工具服务器
```

它规定了：

+ 怎么声明工具
+ 怎么调用
+ 怎么返回结果

你可以理解为：

AI 世界的 gRPC 协议

现在很多 IDE、AI Agent 都在支持 MCP。



## LLM + RAG + Agent + MCP 关系图
我帮你理一下层级：

```plain
         LLM（大脑）
              ↑
         RAG（给资料）
              ↑
         Agent（做决策+调用工具）
              ↑
         MCP（工具协议）
```

再通俗一点：

| 名词 | 是什么 | 类比 |
| --- | --- | --- |
| LLM | 大脑 | 人 |
| RAG | 查资料 | 搜索引擎 |
| Agent | 会干活的 AI | 员工 |
| LangChain | 开发框架 | Spring |
| LangGraph | 工作流引擎 | Temporal |
| MCP | 工具通信协议 | gRPC |


## 一句话记住这些名词
记住这句话：

**LLM 是大脑，RAG 是查资料，Agent 是会干活的员工，LangChain 是开发框架，LangGraph 是工作流，MCP 是工具通信协议。**

现在还不懂是正常的。

因为：

Agent 不是 AI 专业知识，而是一种新的系统架构范式。

## 为什么现在这么火？
因为现在 AI 从：

“会聊天”

升级成：

“会干活”

公司真正要的是：

+ 自动运营 Agent
+ 自动 BI 分析 Agent
+ 自动客服 Agent
+ 自动代码生成 Agent

而不是聊天机器人。

## Go 后端，其实优势巨大
因为 Agent 真正难的不是：

+ 调 API
+ 写 Prompt

而是：

+ 工具设计
+ 并发控制
+ 超时重试
+ 状态管理
+ 成本控制
+ 日志追踪
+ 分布式架构

这些你都已经会。

# Prompt 是什么
Prompt = 你给大模型的“输入指令 + 上下文”

就像你在写：

```bash
curl /api?question=xxx
```

这里的 `question=xxx`，本质就是 Prompt。

只是对象从：

+ 传统程序 → LLM（大模型）

---

**最简单理解：Prompt = 给 AI 的需求说明书**

举个最直观的例子：

**你对 AI 说：**

```plain
帮我总结这段文章
```

这一整句话，就是 Prompt。

不是代码  
不是参数结构体  
就是一段自然语言指令。

---

**从后端视角类比（非常重要）**

你现在写后端：

```go
func CalcDiscount(user User) float64 {
    if user.VIP {
        return 0.8
    }
    return 1.0
}
```

**逻辑是你写死的。**

**而用 LLM 时，你变成这样：**

```plain
你是一个电商优惠策略专家，
根据用户是否VIP、消费金额、活跃度，
判断是否给优惠券，并说明理由。
用户信息：
- VIP: 是
- 消费金额: 2000
- 活跃度: 高
```

这一大段文字 = Prompt  
模型会“自己推理”。

---

**真实 API 里 Prompt 长啥样？**

比如调用大模型接口（伪代码）：

```json
{
  "model": "gpt-4",
  "messages": [
    {
      "role": "system",
      "content": "你是一个资深数据分析师"
    },
    {
      "role": "user",
      "content": "分析最近7天的用户增长趋势"
    }
  ]
}
```

这里：

+ system + user 的 content
+ 全部加起来 = Prompt

---

## Prompt 的三种常见类型（面试会问）
**System Prompt（系统提示）**

定义 AI 的“人设”和规则：

```plain
你是一个严谨的后端工程师，
回答要简洁、专业、给出代码示例。
```

作用：

控制 AI 的行为风格

---

**User Prompt（用户问题）**

就是用户真实输入：

```plain
Redis bitmap 怎么做签到？
```

---

**Context Prompt（上下文）**

给模型额外资料：

```plain
数据库查询结果：
day1: 100
day2: 230
day3: 180
请分析趋势
```

这在 RAG 里非常常见。

## 好 Prompt vs 差 Prompt 对比
**❌**** 差 Prompt**

```plain
分析数据
```

问题：

+ 太模糊
+ 输出不稳定
+ 结果随机

---

**✅**** 好 Prompt（工程级）**

```plain
你是一名资深BI数据分析师。
请根据提供的数据：
1. 分析趋势
2. 找出异常点
3. 给出业务建议
输出格式：
- 趋势：
- 异常：
- 建议：
数据：
{json数据}
```

特点：

+ 角色明确
+ 任务明确
+ 输出格式固定
+ 可控性强（工程必备）

## 在 Agent 里 Prompt 更高级（关键）
在 Agent 系统中，Prompt 不只是问问题，而是：

```plain
你是一个AI助手，
你可以使用以下工具：
1. 查询数据库
2. 调用搜索API
3. 生成报告
当需要数据时，必须优先调用工具，而不是编造答案。
```

这个 Prompt 直接决定：

+ 什么时候调用工具
+ 怎么推理
+ 是否胡说八道（幻觉）

## 现在阶段需要掌握到什么程度
作为 Go 后端，不需要学“花里胡哨的提示词技巧”，只要会：

+ 角色设定（Role）
+ 任务拆解（Task）
+ 输出格式控制（JSON/结构化）
+ 防幻觉约束（必须基于数据回答）

就已经超过 80% 初级 AI 工程师了。

## 程序员版终极理解（强烈建议记住）
> Prompt = 写给大模型的“动态业务逻辑”
>

以前：

```plain
写死业务规则
```

现在：

```plain
用 Prompt 描述业务规则，让 LLM执行
```

这就是为什么很多人说：

未来一部分“业务逻辑”会从代码转移到 Prompt。

## Q1：Prompt Engineering 是什么？（100%会问）
**标准面试回答（推荐背这个思路）**

口语版（最适合面试）：

> Prompt Engineering 本质是通过设计输入指令、上下文和输出约束，让大模型按预期稳定完成任务的一种工程方法。  
因为 LLM 的行为高度依赖输入文本，所以好的 Prompt 相当于在“用自然语言编写动态业务逻辑”。
>

再加一句工程视角（加分）：

> 在实际项目中，Prompt 不只是问问题，还包括角色设定、任务拆解、格式约束和工具调用指令。
>

---

**程序员版理解（你说出来很加分）**

可以这样说：

> 传统后端是把业务逻辑写在代码里，而 AI 系统很多业务逻辑是通过 Prompt 来驱动模型决策。
>

这句话面试官基本会点头。

## Q2：如何让 LLM 输出稳定格式（比如 JSON）？
这是最最最高频的工程问题。

因为：

模型默认输出是“自然语言”，而系统需要“结构化数据”。

---

### 最基础方法：明确输出格式（强约束）
❌ 差 Prompt：

```plain
帮我分析用户数据
```

**输出会乱七八糟。**

✅ 工程级 Prompt：

```plain
你是一个数据分析助手。
请严格按照以下 JSON 格式输出，不要输出任何额外文字：

{
  "trend": "",
  "risk": "",
  "suggestion": ""
}

数据如下：
{data}
```

核心原则：

+ 写明“严格按照 JSON 输出”
+ 给出示例结构
+ 禁止额外解释

---

### 进阶方法（公司真实在用）：Few-shot 示例
给模型示例输入输出：

```plain
示例：
输入：用户增长100 → 输出：
{
  "trend": "上升",
  "risk": "无",
  "suggestion": "继续投放"
}

现在请分析：
输入：用户增长-20
```

效果：

稳定性大幅提升（非常实用）

### 工程最稳方案（面试加分点）
三层保险（强烈推荐你说这个）：

1）Prompt 约束格式  
2）使用模型的 JSON/Function Calling 模式  
3）后端做 JSON 校验和重试机制

后端视角回答示例：

在生产环境我不会只依赖 Prompt，而是配合结构化输出模式和后处理校验，保证格式100%可解析。

这句话非常“高级工程师”。

## Q3：如何通过 Prompt 减少幻觉（Hallucination）？
幻觉 = 模型编造事实（AI最大工程问题）

比如：

+ 编造不存在的数据
+ 瞎写接口结果
+ 乱编业务逻辑

面试官特别爱问这个。

---

### 方法一：提供真实上下文（最有效）
也就是 RAG 思想：

❌ 不给数据：

```plain
分析公司营收
```

模型会瞎编。

---

✅ 给上下文：

```plain
你必须基于以下数据回答，不允许编造：
2024营收：100万
2025营收：150万
请分析增长情况
```

核心原则：

用真实数据“限制模型想象空间”

---

### 方法二：强约束禁止编造（简单但有效）
工程常用写法：

```plain
如果信息不足，请回答“信息不足”，
不要编造任何内容。
```

这句在企业 Prompt 里出现频率极高。

### 方法三：工具优先策略（Agent高级用法）
在 Agent 系统里会写：

```plain
当问题涉及数据时，
必须优先调用数据库工具，
禁止直接凭知识回答。
```

这样模型会：

+ 先查 DB
+ 再回答  
而不是瞎猜。

### 方法四（面试高加分）：降低开放性
❌ 开放问题：

```plain
评价这个产品
```

容易胡说。

✅ 收敛任务：

```plain
根据提供的用户评分(1-5)，
总结优缺点，不要添加额外信息。
```

越具体 → 幻觉越少。

## 面试官最爱听的“总结金句”（强烈建议记住）
你可以这样总结三题（通杀面试）：

Prompt Engineering 本质是通过角色设定、任务拆解、上下文注入和输出约束，让 LLM 的行为可控、稳定、可复现。  
在工程实践中，我通常会通过结构化输出、Few-shot 示例、RAG 提供真实数据，以及“禁止编造”的约束来降低幻觉，并结合后端校验和重试机制保证系统稳定性。

这段回答：

+ 有技术深度
+ 有工程思维
+ 非常像真实做过项目的人

# 高频面试八股
## 什么是 Function Calling？为什么重要？
**标准回答（简洁版）**

Function Calling 是让 LLM 以结构化方式调用外部工具的一种机制。  
模型不直接输出自然语言，而是输出函数名和参数，由后端执行真实逻辑。

---

**<font style="background-color:#FBDE28;">工程加分回答</font>**

**你可以补一句：**

**在生产环境我更倾向使用 Function Calling 或 JSON Mode，而不是解析自然语言，因为这样更稳定、可控、可校验。**

---

**面试官真正想听**

+ 你是否理解 Agent 本质是“LLM + 工具”
+ 你是否知道结构化调用比 Prompt 解析更稳定

---

**本质理解**

以前：

```plain
LLM：帮我查数据库
（自然语言）
```

现在：

```plain
{
  "function": "query_user",
  "args": { "uid": 1001 }
}
```

这就是 AI 世界的 RPC。

---

## RAG 和 微调（Fine-tune）有什么区别？
这个是 100% 会问的问题。

**标准回答**

> RAG 是通过检索外部知识增强模型输入；  
微调是修改模型参数，让模型“长期记住”知识或风格。
>

---

**对比表（面试直接说这个）**

| 维度 | RAG | 微调 |
| --- | --- | --- |
| 是否改模型参数 | ❌ 不改 | ✅ 会改 |
| 更新成本 | 低 | 高 |
| 适合场景 | 企业知识库 | 固定风格/任务 |
| 数据更新 | 实时 | 需要重新训练 |


**工程加分点**

> 在企业内部知识场景，大部分情况优先用 RAG，而不是微调，因为成本低、更新快、风险小。
>

---

## Token 是什么？为什么重要？
**简单回答**

> Token 是模型处理文本的最小单位。模型的计算成本、上下文长度、价格都和 token 数量直接相关。
>

---

**面试官真正想听**

+ 你是否知道成本控制
+ 你是否知道上下文窗口限制

---

**工程回答升级版**

> 在生产系统中，我会限制输入长度、做文本分块（chunking）、以及做缓存，来控制 token 消耗和响应延迟。
>

这句非常工程。

---

## temperature 是什么？怎么调？
**标准回答**

> temperature 控制输出随机性。  
越低越稳定，越高越发散。
>

---

**面试官加分回答**

> 在数据分析或结构化任务中，我会使用低 temperature（0-0.3），保证输出稳定；  
在创意生成场景中，可以调高一点。
>

说明你知道什么时候用什么。

## 什么是 Agent？
**标准回答**

> Agent 是基于 LLM 的自主决策系统，它可以根据任务动态调用工具、分解步骤并完成复杂任务。
>

---

**高级一点的回答**

> Agent 的核心不是“会聊天”，而是“会决策 + 会调用工具”。
>

---

**面试官可能追问**

+ 单 Agent vs 多 Agent 区别？
+ 如何避免死循环？
+ 如何做超时控制？

这时你往工程上答。

## 如何设计一个智能客服 Agent？
**1️⃣**** 架构**

```json
用户 → API → Agent Orchestrator → LLM
                              ↓
                           Tools
                        （知识库/DB）
```

**2️⃣**** 核心模块**

+ Prompt 管理
+ RAG 检索
+ 工具调用
+ 日志系统
+ 成本控制
+ 超时机制

**3️⃣**** 稳定性策略（加分）**

+ 设置最大推理步数
+ 设置工具调用超时
+ 记录 reasoning trace
+ JSON 校验 + 重试

说这些，你就是偏高级工程师思路。

---

## 如何避免 Agent 无限调用工具？
面试可能会问。

你答：

> + 限制最大步骤数（max iterations）
> + 检查重复调用
> + 设置超时
> + 监控 token 消耗
>

说明你考虑过生产问题。

---

## LLM 系统的最大工程挑战是什么？
面试加分回答：

> 不确定性和可控性。
>

然后展开：

+ 输出不稳定
+ 成本不可预测
+ 幻觉问题
+ 上下文爆炸
+ 延迟问题

如果你说这些，面试官会觉得你真的理解。



# Agent 概念图
好 👍 我给你画一套**从简单到完整的 Agent 概念图**，保证你一次性理清。

我会分 4 层讲：

1️⃣ 只有 LLM  
2️⃣ LLM + RAG  
3️⃣ LLM + Tools（Agent 雏形）  
4️⃣ 完整 Agent 系统架构

---

## 最基础：只有 LLM（会聊天）
```plain
用户
  ↓
LLM
  ↓
回答
```

比如：

+ OpenAI 的 GPT
+ Anthropic 的 Claude

本质：

> 大模型只能根据已有知识“猜”答案
>

问题：

+ 不知道你数据库
+ 不知道实时数据
+ 不知道公司内部资料
+ 不能调用接口

它只是“大脑”，没有手脚。

---

## 升级：LLM + RAG（会查资料）
```plain
           ┌────────────┐
           │ 知识库/DB  │
           └──────┬─────┘
                  │
用户 → 检索 → 把资料塞进Prompt → LLM → 输出
```

这就是 RAG（检索增强生成）。

逻辑：

1. 用户提问
2. 系统去数据库 / 向量库查资料
3. 把查到的数据拼进 Prompt
4. 再让 LLM 生成答案

作用：

> 让 AI 知道你公司的“私有数据”
>

RAG 解决的是：

✅ 知识问题  
❌ 不能执行任务

---

## 再升级：LLM + Tools（Agent 雏形）
现在加上“工具”。

```plain
              ┌────────────┐
              │   数据库    │
              ├────────────┤
              │  外部API    │
              ├────────────┤
              │  代码执行器 │
              └──────┬─────┘
                     ↑
用户 → LLM（思考） → 决定调用哪个工具 → 再思考 → 输出
```

重点来了：

> LLM 不只是回答问题，而是决定“我要做什么”。
>

例如：

用户说：

> “帮我分析最近3天转化率最高的广告，并给建议”
>

Agent 内部流程：

```plain
Step1: 我需要查数据库
Step2: 调用SQL工具
Step3: 得到结果
Step4: 分析数据
Step5: 输出报告
```

这就是 Agent。

核心特征：

+ 自主决策
+ 调用工具
+ 多步执行

---

## 完整 AI Agent 架构图（工程版）
这是公司真正用的结构。

```plain
                     用户
                       ↓
              ┌────────────────┐
              │   API Gateway   │
              └────────┬───────┘
                       ↓
              ┌────────────────┐
              │ Agent Orchestrator │
              │  (状态管理/流程控制) │
              └────────┬───────┘
                       ↓
                ┌────────────┐
                │     LLM     │
                └──────┬─────┘
                       ↓
         ┌─────────────────────────┐
         │        Tools Layer       │
         │  ┌──────────────┐       │
         │  │ DB Tool       │       │
         │  │ Search Tool   │       │
         │  │ BI Tool       │       │
         │  │ Code Tool     │       │
         │  └──────────────┘       │
         └─────────────────────────┘
```

解释每一层：

---

### 🔹 LLM（大脑）
+ 负责推理
+ 决定下一步干什么
+ 生成语言

---

### 🔹 Tools（手和脚）
+ 查数据库
+ 调接口
+ 发消息
+ 执行代码

---

### 🔹 Orchestrator（调度中心）
+ 管理多步执行
+ 记录状态
+ 控制超时重试
+ 防止死循环

这部分其实最考验后端能力。

---

## LangChain / LangGraph 在哪一层？
+ LangChain  
👉 帮你构建 Agent（工具管理 + Prompt管理）
+ LangGraph  
👉 做复杂工作流（类似状态机）

你可以理解为：

| 名称 | 在架构中位置 |
| --- | --- |
| LLM | 核心推理层 |
| RAG | 数据增强层 |
| Agent | 决策执行层 |
| LangChain | 开发框架 |
| LangGraph | 工作流引擎 |


---

## 终极理解版本（超通俗）
想象公司里有个新人：

+ LLM = 聪明实习生（会思考）
+ RAG = 给他公司资料
+ Tools = 给他电脑和系统权限
+ Agent = 让他能自己做事
+ LangChain = 管理他的流程
+ Orchestrator = 主管

当他：

+ 会查数据
+ 会调用系统
+ 会自己决定步骤

他就不是聊天机器人了。

他变成员工。

---

## 真正需要理解的只有一句话
> Agent = LLM（思考） + Tools（执行） + Workflow（流程控制）
>

其他名词都是围绕这句话展开。

---





